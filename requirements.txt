# vLLM Project Requirements
# Complete requirements with resolved dependencies
# Install with: pip install -r requirements.txt

# ===== Core Dependencies =====
# vLLM and ML frameworks
vllm==0.5.4
# vLLM 0.5.4 requires torch==2.4.0
torch==2.4.0
# vLLM 0.5.4 requires transformers>=4.43.2
transformers>=4.43.2
accelerate>=0.25.0  # Allow newer versions for compatibility
sentencepiece==0.1.99
protobuf==4.25.1
einops==0.7.0

# ===== vLLM Additional Dependencies =====
# These are required by vLLM but not always auto-installed
outlines==0.0.46  # Specific version that works with vLLM 0.5.4
pyairports  # Required by outlines - let pip resolve version
jsonschema>=4.0.0  # Required for schema validation

# ===== Version Constraints (to avoid conflicts) =====
# CRITICAL: These specific versions prevent dependency conflicts
packaging==23.2  # Required by langfuse and limits
urllib3==1.26.18  # Required by kubernetes
click==8.1.7  # Required by ray

# ===== API and Web Server =====
# Note: FastAPI version may need adjustment based on other dependencies
fastapi>=0.104.1  # Made flexible to avoid starlette conflicts
uvicorn[standard]>=0.24.0  # Made flexible
pydantic>=2.5.0  # Made flexible for compatibility
python-multipart==0.0.6
httpx==0.25.2
aiohttp==3.9.1
aiofiles==23.2.1

# ===== Data Processing =====
numpy==1.24.3
pandas==2.1.4
scipy==1.11.4
scikit-learn==1.3.2

# ===== Monitoring and Observability =====
prometheus-client==0.19.0
opentelemetry-api==1.21.0
opentelemetry-sdk==1.21.0
# opentelemetry-instrumentation-fastapi==0.42b0  # May conflict with FastAPI versions
langfuse==2.20.0
arize-phoenix==4.5.0
# Optional: prometheus-fastapi-instrumentator (install separately if needed)

# ===== Visualization =====
plotly==5.18.0
matplotlib==3.8.2

# ===== Google Cloud Platform =====
google-cloud-storage==2.13.0
google-cloud-monitoring==2.16.0
google-cloud-logging==3.8.0
google-cloud-aiplatform==1.38.1

# ===== Model Management =====
huggingface-hub==0.36.0  # Compatible with transformers 4.57.1
safetensors>=0.4.1  # Allow newer versions for transformers compatibility
# vLLM 0.5.4 requires tokenizers>=0.19.1
tokenizers>=0.19.1
sentence-transformers==2.2.2  # For intelligent routing

# ===== Database and Caching =====
redis==5.0.1
sqlalchemy==2.0.23
alembic==1.13.0

# ===== Utilities =====
python-dotenv==1.0.0
pyyaml==6.0.1
click==8.1.7
rich==13.7.0
tqdm==4.66.1
psutil==5.9.6
gputil==1.4.0

# ===== Testing =====
pytest==7.4.3
pytest-asyncio==0.21.1
pytest-cov==4.1.0
pytest-mock==3.12.0
pytest-benchmark==4.0.0
pytest-xdist==3.5.0
hypothesis==6.92.1
faker==21.0.0

# ===== Code Quality =====
black==23.12.0
ruff==0.1.8
mypy==1.7.1
isort==5.13.2
pylint==3.0.3
bandit==1.7.5

# ===== Documentation =====
mkdocs==1.5.3
mkdocs-material==9.5.2
mkdocstrings[python]==0.24.0
pydoc-markdown==4.8.2

# ===== Development Tools =====
ipython==8.18.1
jupyter==1.0.0
notebook==7.0.6
ipywidgets==8.1.1

# ===== Performance Profiling =====
py-spy==0.3.14
memory-profiler==0.61.0
line-profiler==4.1.1

# ===== Additional ML Tools =====
datasets>=2.14.5  # HuggingFace datasets - allow newer versions
evaluate>=0.4.1    # Model evaluation - allow newer versions
wandb==0.16.1      # Experiment tracking (optional)

# ===== Security =====
cryptography==41.0.7
pyjwt==2.8.0
python-jose[cryptography]==3.3.0
passlib[bcrypt]==1.7.4

# ===== Rate Limiting and Caching =====
slowapi==0.1.9
limits==3.6.0  # Correct package name (not python-limits)
aiocache==0.12.2

# ===== Docker and Deployment =====
docker==6.1.3
kubernetes==28.1.0