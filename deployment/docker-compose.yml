version: '3.8'

services:
  vllm-server:
    build:
      context: ..
      dockerfile: deployment/Dockerfile
    image: vllm-enterprise:latest
    container_name: vllm-production

    # GPU configuration
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

    # Environment variables
    environment:
      - MODEL_NAME=${MODEL_NAME:-microsoft/phi-2}
      - GPU_MEMORY_UTILIZATION=${GPU_MEMORY_UTILIZATION:-0.9}
      - MAX_MODEL_LEN=${MAX_MODEL_LEN:-2048}
      - QUANTIZATION=${QUANTIZATION:-fp8}
      - DTYPE=${DTYPE:-auto}
      - HOST=0.0.0.0
      - PORT=8000
      - TRUST_REMOTE_CODE=True
      - LOG_LEVEL=${LOG_LEVEL:-info}

    # Port mapping
    ports:
      - "8000:8000"

    # Volume mounts
    volumes:
      - model-cache:/app/models
      - ./logs:/app/logs
      - ../.env:/app/.env:ro  # Optional: for secrets

    # Restart policy
    restart: unless-stopped

    # Health check
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

    # Resource limits (optional)
    # mem_limit: 32g
    # cpus: 8.0

  # Optional: Prometheus for monitoring (Blog 3)
  # prometheus:
  #   image: prom/prometheus:latest
  #   container_name: prometheus
  #   ports:
  #     - "9090:9090"
  #   volumes:
  #     - ./prometheus.yml:/etc/prometheus/prometheus.yml
  #     - prometheus-data:/prometheus
  #   command:
  #     - '--config.file=/etc/prometheus/prometheus.yml'
  #   depends_on:
  #     - vllm-server

  # Optional: Grafana for dashboards (Blog 3)
  # grafana:
  #   image: grafana/grafana:latest
  #   container_name: grafana
  #   ports:
  #     - "3000:3000"
  #   volumes:
  #     - grafana-data:/var/lib/grafana
  #   depends_on:
  #     - prometheus

volumes:
  model-cache:
    driver: local
  # prometheus-data:
  # grafana-data:
